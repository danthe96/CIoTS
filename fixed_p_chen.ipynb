{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of CIoTS failed: Traceback (most recent call last):\n",
      "  File \"/home/marcus/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 246, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/marcus/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 369, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/marcus/anaconda3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/marcus/anaconda3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/marcus/Studium/Master/Semester_1/Causality/github/CIoTS/CIoTS/__init__.py\", line 2, in <module>\n",
      "    from .pc_chen_algorithm import pc_chen, pc_chen_modified\n",
      "ImportError: cannot import name 'pc_chen_modified'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from CIoTS import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ps = list(range(4, 9, 2))\n",
    "test_ps = list(range(2, 11, 2))\n",
    "runs = 20\n",
    "dimensions = 4\n",
    "data_length = 10000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = pd.DataFrame(columns=['true_p', 'p', 'mean_f1', 'std_f1'])\n",
    "runtimes = pd.DataFrame(columns=['true_p', 'p', 'mean_time', 'std_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: p=4 run=1 p_test=2 exec_time=3.8553874492645264\n",
      "done: p=4 run=1 p_test=4 exec_time=21.73862886428833\n",
      "done: p=4 run=1 p_test=6 exec_time=70.96734261512756\n",
      "done: p=4 run=1 p_test=8 exec_time=206.01968455314636\n"
     ]
    }
   ],
   "source": [
    "for p in max_ps:\n",
    "    incoming_edges = 3 #max(ceil(dimensions*p/3), 1)\n",
    "    \n",
    "    f1 = {p_test: [] for p_test in test_ps}\n",
    "    runtime = {p_test: [] for p_test in test_ps}\n",
    "    \n",
    "    for run in range(runs):\n",
    "        generator = CausalTSGenerator(dimensions=dimensions, max_p=p, data_length=data_length, incoming_edges=incoming_edges)\n",
    "        ts = generator.generate()\n",
    "            \n",
    "        for p_test in test_ps:\n",
    "            start_time = time.time()\n",
    "            predicted_graph = pc_chen(partial_corr_test, ts, p_test, alpha)\n",
    "            exec_time = time.time()-start_time\n",
    "            \n",
    "            f1[p_test].append(evaluate_edges(generator.graph, predicted_graph)['f1-score'])\n",
    "            runtime[p_test].append(exec_time)\n",
    "            print('done: p='+ str(p) + ' run='+str(run+1) + ' p_test='+str(p_test) + ' exec_time='+str(exec_time))\n",
    "    \n",
    "    for p_test in test_ps:\n",
    "        f1_scores = f1_scores.append({'true_p': p, 'p': p_test, 'mean_f1': np.mean(f1[p_test]),\n",
    "                                      'std_f1': np.std(f1[p_test])}, ignore_index=True)\n",
    "        runtimes = runtimes.append({'true_p': p, 'p': p_test, 'mean_time': np.mean(runtime[p_test]),\n",
    "                                    'std_time': np.std(runtime[p_test])}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('f1 scores for differen p')\n",
    "plt.xlabel('assumed p')\n",
    "plt.ylabel('mean f1')\n",
    "handles = []\n",
    "labels = []\n",
    "for p in max_ps:\n",
    "    plt.errorbar(x=f1_scores.loc[f1_scores['true_p']==p, 'p'],\n",
    "                 y=f1_scores.loc[f1_scores['true_p']==p, 'mean_f1'],\n",
    "                 yerr=f1_scores.loc[f1_scores['true_p']==p, 'std_f1'],\n",
    "                 label='true p='+str(p))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
