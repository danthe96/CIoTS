{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-29T10:42:57.797358Z",
     "start_time": "2019-01-29T10:42:57.770377Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:58:25.107129Z",
     "start_time": "2019-01-30T19:58:21.925095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import r-package RCIT\n",
      "Could not import r-package acepack for GPACE, use python ACE package\n",
      "Could not import python ACE package for GPACE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.getcwd().endswith('CIoTS'):\n",
    "    os.chdir('../..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from CIoTS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper: check if data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:58:25.465368Z",
     "start_time": "2019-01-30T19:58:25.447313Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def check_setups(setups, data_path):\n",
    "    return not missing_setups(setups, data_path)\n",
    "\n",
    "def missing_setups(setups, data_path):\n",
    "    missing = []\n",
    "    for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "        if not os.path.isfile(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle'):\n",
    "            missing.append((dim, in_edges, tau, autocorr, run))\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-30T19:58:27.085435Z",
     "start_time": "2019-01-30T19:58:27.076746Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "dimensions = [3,5,10]\n",
    "incoming_edges = [2,3,4]\n",
    "taus = [5,10,15,20]\n",
    "autocorrs = [False, True]\n",
    "data_length = [10000]\n",
    "runs = range(10)\n",
    "\n",
    "\n",
    "setups = list(product(dimensions, incoming_edges, taus, autocorrs, data_length, runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime for inc vs. non-inc\n",
    "\n",
    "PC1 iterative vs. PC1 non-iterative iterative\n",
    "\n",
    "Also check for $\\tau - k$ and $\\tau + k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-30T19:58:44.787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Daniel.Thevessen/Causality/CIoTS/src/tigramite/tigramite/independence_tests.py:1144: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  beta_hat = numpy.linalg.lstsq(z, y)[0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from time import time\n",
    "\n",
    "data_path = 'notebooks/ICML/icml_data_v2/'\n",
    "results_path = 'notebooks/ICML/icml_results_v2/'\n",
    "results = pd.DataFrame()\n",
    "k = 2\n",
    "\n",
    "if not check_setups(setups, data_path):\n",
    "    print('Mising setups:')\n",
    "    print(missing_setups(setups, data_path))\n",
    "\n",
    "for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "    generator = pickle.load(open(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle', 'rb'))\n",
    "    \n",
    "    df_dict = {'dimension': dim, 'max time lag': tau, 'incoming edges': in_edges, 'run': run, 'autocorr': autocorr}\n",
    "    \n",
    "    # incremental\n",
    "    stopper = ICStopper(dim=dim, patiency=2)\n",
    "    start_time = time()\n",
    "    pc_incremental_pc1(tigramite_partial_corr_test, ts=generator.ts, max_p=2*tau, stopper=stopper, verbose=False)\n",
    "    time_delta = time() - start_time\n",
    "    df_dict['PC1 incremental - runtime'] = time_delta\n",
    "    \n",
    "    # non-incremental\n",
    "    for offset in range(-k, k+1):\n",
    "        offset_str = f'{offset:+}' if offset != 0 else ''\n",
    "        start_time = time()\n",
    "        pc_incremental_pc1(tigramite_partial_corr_test, ts=generator.ts, \n",
    "                           start=0, step=tau+offset, max_p=tau+offset, verbose=False)\n",
    "        time_delta = time() - start_time\n",
    "        df_dict[f'PC1 tau{offset_str} - runtime'] = time_delta\n",
    "\n",
    "    results = results.append(df_dict, ignore_index=True)\n",
    "    results.to_csv(results_path + f'experiment5b.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Incremental vs Non-Incremental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1. Visualize $F_1$ for known $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T10:56:27.914Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import sys\n",
    "eps = sys.float_info.epsilon\n",
    "\n",
    "def plot_f1_groupedbarchart(df_dict, title):\n",
    "    assert len(df_dict) > 0\n",
    "    #assert reduce(lambda x,y: np.all(x == y), map(lambda e:e.columns, grouped_result.values()))\n",
    "    bar_labels = [f'$\\\\tau + {c[1]}$' if c[1]>=0 else f'$\\\\tau - {abs(c[1])}$'\n",
    "                  for c in next(iter(grouped_result.values())).columns]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ind = np.arange(len(bar_labels))\n",
    "    width = 0.7 / len(df_dict)\n",
    "    \n",
    "    plots = []\n",
    "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for w_idx, (algo, f1s) in enumerate(df_dict.items()):\n",
    "        p = ax.bar(ind + w_idx*width + (width / 2), np.mean(f1s, axis=0), width, \n",
    "                   color=color_cycle[w_idx % len(color_cycle)],\n",
    "                   bottom=0, yerr=np.std(f1s, axis=0))\n",
    "        plots.append(p[0])\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(ind + (len(df_dict) * width) / 2)\n",
    "    ax.set_xticklabels(bar_labels)\n",
    "\n",
    "    ax.legend(plots, df_dict.keys())\n",
    "    ax.autoscale_view()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T10:56:27.916Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = 'notebooks/ICML/icml_results_v2/'\n",
    "algorithms = [(pc_incremental, 'PC incremental'),\n",
    "              (pc_incremental_extensive, 'PC extensive'),\n",
    "              (pc_incremental_pc1, 'PC1 incremental'),\n",
    "              (pc_incremental_pc1mci, 'PCMCI incremental')]\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment1.csv')\n",
    "for group, result in results.groupby(['max time lag', 'autocorr']): # Group by ['dimension', 'incoming edges', 'autocorr'] as well?\n",
    "    tau = int(group[0])\n",
    "    autocorr = float(group[1])\n",
    "    grouped_result = {}\n",
    "    for algorithm, name in algorithms:\n",
    "        algo_cols = [col for col in result.columns if col[:col.rfind('_')] == name]\n",
    "        df = result[algo_cols].rename(lambda c:('f1', int(c.split('_')[-1][2:])), axis='columns')\n",
    "        grouped_result[name] = df[sorted(df.columns)]\n",
    "    plot_f1_groupedbarchart(grouped_result, title=f'$F_1$ score for known $\\\\tau$ = {tau}, autocorr = {autocorr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 2. Visualize estimate $\\hat{\\tau}$ for unknown $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T10:56:27.960Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "visualize = [(10, 2, False)]\n",
    "names = ['PC1 incremental: BIC', 'PC1 incremental: Correlation',\n",
    "         'VAR: BIC', 'PC incremental: BIC', 'PC extensive: BIC', 'PCMCI: BIC']\n",
    "\n",
    "width = 0.4\n",
    "results_path = 'notebooks/ICML/icml_results_v2/'\n",
    "cols = [name + '_tau' for name in names]\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment2.csv')\n",
    "true_taus = np.unique(results['max time lag'])\n",
    "\n",
    "for group, result in results.groupby(['dimension', 'incoming edges', 'autocorr']): \n",
    "    \n",
    "    if group not in visualize:\n",
    "        continue\n",
    "    \n",
    "    dim = int(group[0])\n",
    "    in_edges = int(group[1])\n",
    "    autocorr = float(group[2])\n",
    "    \n",
    "    colors = plt.cm.CMRmap(np.linspace(0,1,len(names)+2))\n",
    "    plt.figure(dpi=200, figsize=(15, 8))\n",
    "    \n",
    "    \n",
    "    for tau in true_taus:\n",
    "        start_x = tau - (width+0.1)*(len(names))/2\n",
    "        end_x = tau + (width+0.1)*(len(names))/2\n",
    "        y = tau\n",
    "        plt.hlines(y, start_x, end_x, colors='grey')\n",
    "    \n",
    "    bps = []\n",
    "    for i, name in enumerate(names):\n",
    "        positions = [tau + (width+0.1)*(i - (len(names)-1)/2) for tau in true_taus]\n",
    "        arr = [result.loc[result['max time lag']==tau, cols[i]] for tau in true_taus]\n",
    "        bp = plt.boxplot(arr, positions=positions, widths=width, showfliers=False,\n",
    "                         whiskerprops={'color': colors[i+1]}, boxprops={'color': colors[i+1]},\n",
    "                         capprops={'color': colors[i+1]}, medianprops={'color': 'black'})\n",
    "        bps.append(bp)\n",
    "    \n",
    "    plt.xlabel('true $\\\\tau$')\n",
    "    plt.ylabel('estimated $\\\\hat{\\\\tau}$')\n",
    "    plt.xticks(true_taus, true_taus)\n",
    "    plt.title(f'$\\\\tau$ estimation for dimensionality={dim}, incoming edges={in_edges}, autocorr={autocorr}')\n",
    "    plt.xlim(min(true_taus)-(width+0.2)*len(names)/2, max(true_taus)+(width+0.2)*len(names)/2)\n",
    "    \n",
    "    plt.legend([bps[i]['whiskers'][0] for i in range(len(names))], names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Varying patiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T10:56:27.999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simulate_stopping(df, stopping, params, col):\n",
    "    sorted_df = df.sort_values(by='tau estimate')\n",
    "    idx = stopping.simulate(sorted_df[col].values, **params)\n",
    "    return sorted_df['tau estimate'].iloc[idx]\n",
    "\n",
    "from math import floor\n",
    "\n",
    "visualize = [(10, 2, False)]\n",
    "\n",
    "# schema: pc_version, stopper_class, params, column_suffix, name\n",
    "algorithms = [('PC1 incremental', ICStopper, {'patiency': 2}, 'bics', 'PC1: BIC'),\n",
    "              ('PCMCI incremental', ICStopper, {'patiency': 2}, 'bics', 'PCMCI: BIC'),\n",
    "              ('PC extensive', ICStopper, {'patiency': 2}, 'bics', 'PC extensive: BIC'),\n",
    "              ('PC1 incremental', CorrStopper, {'patiency': 2}, 'added_edges', 'PC1: Correlation'),\n",
    "              ('PCMCI incremental', CorrStopper, {'patiency': 2}, 'added_edges', 'PCMCI: Correlation'),\n",
    "              ('PC extensive', CorrStopper, {'patiency': 2}, 'added_edges', 'PC extensive: Correlation')]\n",
    "\n",
    "width = 0.4\n",
    "results_path = 'notebooks/ICML/icml_results_v2/'\n",
    "\n",
    "names = [name for _, _, _, _, name in algorithms]\n",
    "cols = [name + '_tau' for name in names]\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment3.csv')\n",
    "true_taus = np.unique(results['max time lag'])\n",
    "\n",
    "for group, result in results.groupby(['dimension', 'incoming edges', 'autocorr']): \n",
    "    \n",
    "    if group not in visualize:\n",
    "        continue\n",
    "    \n",
    "    dim = int(group[0])\n",
    "    in_edges = int(group[1])\n",
    "    autocorr = float(group[2])\n",
    "    \n",
    "    colors = plt.cm.CMRmap(np.linspace(0,1,len(names)+2))\n",
    "    plt.figure(dpi=200, figsize=(15, 8))\n",
    "    \n",
    "    for tau in true_taus:\n",
    "        start_x = tau - (width+0.1)*(len(names))/2\n",
    "        end_x = tau + (width+0.1)*(len(names))/2\n",
    "        y = tau\n",
    "        plt.hlines(y, start_x, end_x, colors='grey')\n",
    "    \n",
    "    bps = []\n",
    "    for i, (pc, stopper, params, col_suffix, name) in enumerate(algorithms):\n",
    "        col = pc + '_' + col_suffix\n",
    "        positions = [tau + (width+0.1)*(i - (len(names)-1)/2) for tau in true_taus]\n",
    "        arr = [result[result['max time lag'] == tau].groupby(['run']).apply(\n",
    "            lambda df: simulate_stopping(df, stopper, params, col)).values \n",
    "               for tau in true_taus]\n",
    "        bp = plt.boxplot(arr, positions=positions, widths=width, showfliers=False,\n",
    "                         whiskerprops={'color': colors[i+1]}, boxprops={'color': colors[i+1]},\n",
    "                         capprops={'color': colors[i+1]}, medianprops={'color': 'black'})\n",
    "        bps.append(bp)\n",
    "    \n",
    "    plt.xlabel('true $\\\\tau$')\n",
    "    plt.ylabel('estimated $\\\\hat{\\\\tau}$')\n",
    "    plt.xticks(true_taus, true_taus)\n",
    "    plt.title(f'$\\\\tau$ estimation for dimensionality={dim}, incoming edges={in_edges}, autocorr={autocorr}')\n",
    "    plt.xlim(min(true_taus)-(width+0.2)*len(names)/2, max(true_taus)+(width+0.2)*len(names)/2)\n",
    "    \n",
    "    plt.legend([bps[i]['whiskers'][0] for i in range(len(names))], names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 3. Visualize iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-18T10:56:28.044Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "visualize = [(20, 3, 4, False)]\n",
    "names = ['PC1 incremental', 'PC extensive', 'PC incremental']\n",
    "prop = 'bics'\n",
    "\n",
    "width = 0.4\n",
    "results_path = 'notebooks/ICML/icml_results_v2/'\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment3.csv')\n",
    "true_taus = np.unique(results['max time lag'])\n",
    "\n",
    "for group, result in results.groupby(['max time lag', 'dimension', 'incoming edges', 'autocorr', 'run']): \n",
    "    \n",
    "    tau = int(group[0])\n",
    "    dim = int(group[1])\n",
    "    in_edges = int(group[2])\n",
    "    autocorr = float(group[3])\n",
    "    run = int(group[4])\n",
    "    \n",
    "    if (tau, dim, in_edges, autocorr) not in visualize:\n",
    "        continue\n",
    "    \n",
    "    colors = plt.cm.CMRmap(np.linspace(0,1,len(names)+2))\n",
    "    plt.figure(dpi=200, figsize=(15, 8))\n",
    "    \n",
    "    x = result['tau estimate']\n",
    "    for i, name in enumerate(names):\n",
    "        y = result[name + '_' + prop]\n",
    "        plt.plot(x, y, color=colors[i+1], label=name)\n",
    "    \n",
    "    plt.xlabel('iteration $\\\\tau$')\n",
    "    plt.ylabel(prop)\n",
    "    plt.title(f'{prop} for dimensionality={dim}, incoming edges={in_edges}, autocorr={autocorr}, run={run}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
