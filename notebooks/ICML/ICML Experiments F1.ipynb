{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-11T16:15:48.477806Z",
     "start_time": "2019-01-11T16:15:47.751372Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:35:41.240449Z",
     "start_time": "2019-01-15T15:35:39.462672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.getcwd().endswith('CIoTS'):\n",
    "    os.chdir('../..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from CIoTS import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper: check if data exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:47:15.666743Z",
     "start_time": "2019-01-15T15:47:15.651171Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def check_setups(setups, data_path):\n",
    "    return not missing_setups(setups, data_path)\n",
    "\n",
    "def missing_setups(setups, data_path):\n",
    "    missing = []\n",
    "    for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "        if not os.path.isfile(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle'):\n",
    "            missing.append((dim, in_edges, tau, autocorr))#, run))\n",
    "    return list(set(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T16:28:18.344810Z",
     "start_time": "2019-01-15T16:28:18.322842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10, 3, 5, True),\n",
       " (10, 3, 10, False),\n",
       " (10, 3, 10, True),\n",
       " (10, 3, 15, False),\n",
       " (10, 3, 15, True),\n",
       " (10, 3, 20, False),\n",
       " (10, 3, 20, True),\n",
       " (10, 4, 5, False),\n",
       " (10, 4, 5, True),\n",
       " (10, 4, 10, False),\n",
       " (10, 4, 10, True),\n",
       " (10, 4, 15, False),\n",
       " (10, 4, 15, True),\n",
       " (10, 4, 20, False),\n",
       " (10, 4, 20, True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(missing_setups(setups, 'notebooks/ICML/icml_data/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:47:24.156474Z",
     "start_time": "2019-01-15T15:47:24.149058Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "dimensions = [3]\n",
    "incoming_edges = [2, 3, 4]\n",
    "taus = [5, 10, 15, 20]\n",
    "autocorrs = [False, True]\n",
    "data_length = [10000]\n",
    "runs = range(10)\n",
    "\n",
    "setups = list(product(dimensions, incoming_edges, taus, autocorrs, data_length, runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compute $F_1$ for known $\\tau$\n",
    "\n",
    "PC1 iterative vs. PC iterative\n",
    "\n",
    "Also check for $\\tau - k$ and $\\tau + k$ to visualize importance of $\\tau$ estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:35:47.008267Z",
     "start_time": "2019-01-15T15:35:47.000700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = 'notebooks/ICML/icml_data/'\n",
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "results = pd.DataFrame()\n",
    "k = 2\n",
    "\n",
    "algorithms = [(pc_incremental, 'PC incremental'),\n",
    "              (pc_incremental_extensive, 'PC extensive'),\n",
    "              (pc_incremental_pc1, 'PC1 incremental')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-15T14:05:15.273Z"
    }
   },
   "outputs": [],
   "source": [
    "if not check_setups(setups, data_path):\n",
    "    print('Missing setups:')\n",
    "    print(missing_setups(setups, data_path))\n",
    "\n",
    "for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "    generator = pickle.load(open(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle', 'rb'))\n",
    "    \n",
    "    df_dict = {'dimension': dim, 'max time lag': tau, 'incoming edges': in_edges, 'run': run, 'autocorr': autocorr}\n",
    "    for algorithm, name in algorithms:\n",
    "        _, graphs, _, _, _ = algorithm(partial_corr_test, generator.ts, max_p=tau+k, \n",
    "                                       use_stopper=False, alpha=0.01, verbose=True)\n",
    "        for offset in range(-k, k+1):\n",
    "            f1_score = evaluate_edges(generator.graph, graphs[tau+offset])['f1-score']\n",
    "            df_dict[name + '_f1' + (f'+{offset}' if offset>=0 else str(offset))] = f1_score\n",
    "\n",
    "    results = results.append(df_dict, ignore_index=True)\n",
    "\n",
    "results.to_csv(results_path + f'experiment1-Alpha001.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add results for non-iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:29:40.560662Z",
     "start_time": "2019-01-15T13:20:58.853334Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(results_path + f'experiment1-Alpha001.csv')\n",
    "for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "    generator = pickle.load(open(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle', 'rb'))\n",
    "    \n",
    "    df_dict = {'dimension': dim, 'max time lag': tau, 'incoming edges': in_edges, 'run': run, 'autocorr': autocorr}\n",
    "    name = 'PC1 non-incremental'\n",
    "\n",
    "    for offset in range(-k, k+1):\n",
    "        _, graphs, _, _, _ = pc_incremental_pc1(partial_corr_test, generator.ts, max_p=tau+offset,\n",
    "                                                steps=tau+offset,\n",
    "                                                use_stopper=False, alpha=0.01, verbose=True)\n",
    "        assert len(graphs) == 1\n",
    "        f1_score = evaluate_edges(generator.graph, graphs[tau+offset])['f1-score']\n",
    "        df_dict[name + '_f1' + (f'+{offset}' if offset>=0 else str(offset))] = f1_score\n",
    "\n",
    "    results = results.append(df_dict, ignore_index=True)\n",
    "results.to_csv(results_path + f'experiment1-Alpha001_incl-non-inc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T15:40:25.002198Z",
     "start_time": "2019-01-15T15:40:24.986142Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(results_path + f'experiment1-Alpha001_incl-non-inc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T17:37:41.487015Z",
     "start_time": "2019-01-15T17:37:41.481903Z"
    }
   },
   "outputs": [],
   "source": [
    "names = ['PC incremental', 'PC extensive', 'PC1 incremental', 'PC1 non-incremental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T17:37:45.821185Z",
     "start_time": "2019-01-15T17:37:45.814092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PC incremental', 'PC extensive', 'PC1 incremental', 'PC1 non-incremental']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-15T17:42:04.618406Z",
     "start_time": "2019-01-15T17:42:04.567094Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PC incremental_f1+1</th>\n",
       "      <th>PC extensive_f1+1</th>\n",
       "      <th>PC1 incremental_f1+1</th>\n",
       "      <th>PC1 non-incremental_f1+1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimension</th>\n",
       "      <th>incoming edges</th>\n",
       "      <th>autocorr</th>\n",
       "      <th>max time lag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"24\" valign=\"top\">3.0</th>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.694929</td>\n",
       "      <td>0.694602</td>\n",
       "      <td>0.688177</td>\n",
       "      <td>0.743502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.862987</td>\n",
       "      <td>0.864719</td>\n",
       "      <td>0.880136</td>\n",
       "      <td>0.976623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.942105</td>\n",
       "      <td>0.922711</td>\n",
       "      <td>0.956044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.860865</td>\n",
       "      <td>0.855151</td>\n",
       "      <td>0.767010</td>\n",
       "      <td>0.828967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.641513</td>\n",
       "      <td>0.626479</td>\n",
       "      <td>0.675082</td>\n",
       "      <td>0.754808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.617101</td>\n",
       "      <td>0.547913</td>\n",
       "      <td>0.622169</td>\n",
       "      <td>0.831214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.716766</td>\n",
       "      <td>0.725814</td>\n",
       "      <td>0.684293</td>\n",
       "      <td>0.881012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.768450</td>\n",
       "      <td>0.784632</td>\n",
       "      <td>0.757947</td>\n",
       "      <td>0.761456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3.0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.776996</td>\n",
       "      <td>0.788490</td>\n",
       "      <td>0.646054</td>\n",
       "      <td>0.675059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.667173</td>\n",
       "      <td>0.639247</td>\n",
       "      <td>0.578397</td>\n",
       "      <td>0.750288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.776260</td>\n",
       "      <td>0.785744</td>\n",
       "      <td>0.893867</td>\n",
       "      <td>0.959474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.656708</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.778997</td>\n",
       "      <td>0.795598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.646031</td>\n",
       "      <td>0.637137</td>\n",
       "      <td>0.539836</td>\n",
       "      <td>0.536931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.766536</td>\n",
       "      <td>0.767698</td>\n",
       "      <td>0.584791</td>\n",
       "      <td>0.619347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.657270</td>\n",
       "      <td>0.620337</td>\n",
       "      <td>0.641796</td>\n",
       "      <td>0.646327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.613032</td>\n",
       "      <td>0.622075</td>\n",
       "      <td>0.637911</td>\n",
       "      <td>0.666603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">4.0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.634991</td>\n",
       "      <td>0.634991</td>\n",
       "      <td>0.596047</td>\n",
       "      <td>0.655412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.650663</td>\n",
       "      <td>0.667719</td>\n",
       "      <td>0.507659</td>\n",
       "      <td>0.658986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.676684</td>\n",
       "      <td>0.696288</td>\n",
       "      <td>0.725109</td>\n",
       "      <td>0.743436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.733504</td>\n",
       "      <td>0.729221</td>\n",
       "      <td>0.673420</td>\n",
       "      <td>0.800071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1.0</th>\n",
       "      <th>5.0</th>\n",
       "      <td>0.576908</td>\n",
       "      <td>0.582699</td>\n",
       "      <td>0.435970</td>\n",
       "      <td>0.532321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.518046</td>\n",
       "      <td>0.547020</td>\n",
       "      <td>0.486588</td>\n",
       "      <td>0.541434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.497864</td>\n",
       "      <td>0.565410</td>\n",
       "      <td>0.536439</td>\n",
       "      <td>0.617936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.507111</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.561249</td>\n",
       "      <td>0.679520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                PC incremental_f1+1  \\\n",
       "dimension incoming edges autocorr max time lag                        \n",
       "3.0       2.0            0.0      5.0                      0.694929   \n",
       "                                  10.0                     0.862987   \n",
       "                                  15.0                     0.942105   \n",
       "                                  20.0                     0.860865   \n",
       "                         1.0      5.0                      0.641513   \n",
       "                                  10.0                     0.617101   \n",
       "                                  15.0                     0.716766   \n",
       "                                  20.0                     0.768450   \n",
       "          3.0            0.0      5.0                      0.776996   \n",
       "                                  10.0                     0.667173   \n",
       "                                  15.0                     0.776260   \n",
       "                                  20.0                     0.656708   \n",
       "                         1.0      5.0                      0.646031   \n",
       "                                  10.0                     0.766536   \n",
       "                                  15.0                     0.657270   \n",
       "                                  20.0                     0.613032   \n",
       "          4.0            0.0      5.0                      0.634991   \n",
       "                                  10.0                     0.650663   \n",
       "                                  15.0                     0.676684   \n",
       "                                  20.0                     0.733504   \n",
       "                         1.0      5.0                      0.576908   \n",
       "                                  10.0                     0.518046   \n",
       "                                  15.0                     0.497864   \n",
       "                                  20.0                     0.507111   \n",
       "\n",
       "                                                PC extensive_f1+1  \\\n",
       "dimension incoming edges autocorr max time lag                      \n",
       "3.0       2.0            0.0      5.0                    0.694602   \n",
       "                                  10.0                   0.864719   \n",
       "                                  15.0                   0.942105   \n",
       "                                  20.0                   0.855151   \n",
       "                         1.0      5.0                    0.626479   \n",
       "                                  10.0                   0.547913   \n",
       "                                  15.0                   0.725814   \n",
       "                                  20.0                   0.784632   \n",
       "          3.0            0.0      5.0                    0.788490   \n",
       "                                  10.0                   0.639247   \n",
       "                                  15.0                   0.785744   \n",
       "                                  20.0                   0.670211   \n",
       "                         1.0      5.0                    0.637137   \n",
       "                                  10.0                   0.767698   \n",
       "                                  15.0                   0.620337   \n",
       "                                  20.0                   0.622075   \n",
       "          4.0            0.0      5.0                    0.634991   \n",
       "                                  10.0                   0.667719   \n",
       "                                  15.0                   0.696288   \n",
       "                                  20.0                   0.729221   \n",
       "                         1.0      5.0                    0.582699   \n",
       "                                  10.0                   0.547020   \n",
       "                                  15.0                   0.565410   \n",
       "                                  20.0                   0.500788   \n",
       "\n",
       "                                                PC1 incremental_f1+1  \\\n",
       "dimension incoming edges autocorr max time lag                         \n",
       "3.0       2.0            0.0      5.0                       0.688177   \n",
       "                                  10.0                      0.880136   \n",
       "                                  15.0                      0.922711   \n",
       "                                  20.0                      0.767010   \n",
       "                         1.0      5.0                       0.675082   \n",
       "                                  10.0                      0.622169   \n",
       "                                  15.0                      0.684293   \n",
       "                                  20.0                      0.757947   \n",
       "          3.0            0.0      5.0                       0.646054   \n",
       "                                  10.0                      0.578397   \n",
       "                                  15.0                      0.893867   \n",
       "                                  20.0                      0.778997   \n",
       "                         1.0      5.0                       0.539836   \n",
       "                                  10.0                      0.584791   \n",
       "                                  15.0                      0.641796   \n",
       "                                  20.0                      0.637911   \n",
       "          4.0            0.0      5.0                       0.596047   \n",
       "                                  10.0                      0.507659   \n",
       "                                  15.0                      0.725109   \n",
       "                                  20.0                      0.673420   \n",
       "                         1.0      5.0                       0.435970   \n",
       "                                  10.0                      0.486588   \n",
       "                                  15.0                      0.536439   \n",
       "                                  20.0                      0.561249   \n",
       "\n",
       "                                                PC1 non-incremental_f1+1  \n",
       "dimension incoming edges autocorr max time lag                            \n",
       "3.0       2.0            0.0      5.0                           0.743502  \n",
       "                                  10.0                          0.976623  \n",
       "                                  15.0                          0.956044  \n",
       "                                  20.0                          0.828967  \n",
       "                         1.0      5.0                           0.754808  \n",
       "                                  10.0                          0.831214  \n",
       "                                  15.0                          0.881012  \n",
       "                                  20.0                          0.761456  \n",
       "          3.0            0.0      5.0                           0.675059  \n",
       "                                  10.0                          0.750288  \n",
       "                                  15.0                          0.959474  \n",
       "                                  20.0                          0.795598  \n",
       "                         1.0      5.0                           0.536931  \n",
       "                                  10.0                          0.619347  \n",
       "                                  15.0                          0.646327  \n",
       "                                  20.0                          0.666603  \n",
       "          4.0            0.0      5.0                           0.655412  \n",
       "                                  10.0                          0.658986  \n",
       "                                  15.0                          0.743436  \n",
       "                                  20.0                          0.800071  \n",
       "                         1.0      5.0                           0.532321  \n",
       "                                  10.0                          0.541434  \n",
       "                                  15.0                          0.617936  \n",
       "                                  20.0                          0.679520  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(['dimension', 'incoming edges', 'autocorr', 'max time lag', 'run']\n",
    "               ).min().groupby(['dimension', 'incoming edges', 'autocorr', 'max time lag']).mean(\n",
    "                )[[n + '_f1+1' for n in names]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 2. Compute estimate $\\hat{\\tau}$ for unknown $\\tau$\n",
    "\n",
    "Test VAR estimation vs. Incremental BIC (for $PC_1$) vs. Correltation test based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T10:14:34.135196Z",
     "start_time": "2019-01-14T10:14:20.589Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = 'notebooks/ICML/icml_data/'\n",
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "results = pd.DataFrame()\n",
    "\n",
    "if not check_setups(setups, data_path):\n",
    "    print('Mising setups:')\n",
    "    print(missing_setups(setups, data_path))\n",
    "\n",
    "for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "    generator = pickle.load(open(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle', 'rb'))\n",
    "    \n",
    "    df_dict = {'dimension': dim, 'max time lag': tau, 'incoming edges': in_edges, 'run': run, 'autocorr': autocorr}\n",
    "    algorithms = [\n",
    "        (pc_incremental_pc1, {\n",
    "            'indep_test': partial_corr_test,\n",
    "            'ts': generator.ts,\n",
    "            'max_p': 2*tau,\n",
    "            'stopper': ICStopper(dim, patiency=2, ic='bic'),\n",
    "            'verbose': True}, lambda r: r[3].best_tau, 'PC1 incremental: BIC'),\n",
    "        (pc_incremental_pc1, {\n",
    "            'indep_test': partial_corr_test,\n",
    "            'ts': generator.ts,\n",
    "            'max_p': 2*tau,\n",
    "            'stopper': CorrStopper(dim, patiency=1, max_tau=2*tau),\n",
    "            'verbose': True}, lambda r: r[3].best_tau, 'PC1 incremental: Correlation'),\n",
    "        (var_order_select, {\n",
    "            'ts': generator.ts, \n",
    "            'max_p': 2*tau, \n",
    "            'ics': ['bic']}, lambda r: r[0]['bic'][0], 'VAR: BIC'),\n",
    "        (pc_incremental, {\n",
    "            'indep_test': partial_corr_test,\n",
    "            'ts': generator.ts,\n",
    "            'max_p': 2*tau,\n",
    "            'stopper': ICStopper(dim, patiency=2, ic='bic'),\n",
    "            'verbose': True}, lambda r: r[3].best_tau, 'PC incremental: BIC'),\n",
    "        (pc_incremental_extensive, {\n",
    "            'indep_test': partial_corr_test,\n",
    "            'ts': generator.ts,\n",
    "            'max_p': 2*tau,\n",
    "            'stopper': ICStopper(dim, patiency=2, ic='bic'),\n",
    "            'verbose': True}, lambda r: r[3].best_tau, 'PC extensive: BIC')\n",
    "    ]\n",
    "    for algorithm, params, result_func, name in algorithms:\n",
    "        result = algorithm(**params)\n",
    "        df_dict[name + '_tau'] = result_func(result)\n",
    "    results = results.append(df_dict, ignore_index=True)\n",
    "\n",
    "results.to_csv(results_path + f'experiment2-Alpha001.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluate each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:12:03.672420Z",
     "start_time": "2019-01-14T10:15:30.250891Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data_path = 'notebooks/ICML/icml_data/'\n",
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "results = pd.DataFrame()\n",
    "\n",
    "algorithms = [(pc_incremental, 'PC incremental'),\n",
    "              (pc_incremental_extensive, 'PC extensive'),\n",
    "              (pc_incremental_pc1, 'PC1 incremental')]\n",
    "\n",
    "if not check_setups(setups, data_path):\n",
    "    print('Mising setups:')\n",
    "    print(missing_setups(setups, data_path))   \n",
    "    \n",
    "for dim, in_edges, tau, autocorr, _, run in setups:\n",
    "    generator = pickle.load(open(data_path + f't={tau}_d={dim}_in={in_edges}_autocorr={autocorr}_{run}.pickle', 'rb'))\n",
    "    max_tau = 2 * tau\n",
    "    \n",
    "    df_dict = {'dimension': [dim]*max_tau, 'max time lag': [tau]*max_tau, 'incoming edges': [in_edges]*max_tau, \n",
    "               'run': [run]*max_tau, 'autocorr': [autocorr]*max_tau, 'tau estimate': list(range(1, max_tau+1))}\n",
    "    \n",
    "    for algorithm, name in algorithms:\n",
    "        _, graphs, _, stopper, _ = algorithm(partial_corr_test, generator.ts, max_p=max_tau, \n",
    "                                             use_stopper=False, alpha=0.01, verbose=True)\n",
    "\n",
    "        confusion, confusion_delta = evaluate_edge_deletion(generator.graph,\n",
    "                                                            [{'graph': graphs[t], 'p_iter': t} \n",
    "                                                             for t in range(1, max_tau+1)],\n",
    "                                                            dim)\n",
    "        added_edges = (confusion_delta['tp'] + confusion_delta['fp']).tolist()\n",
    "        f1_scores = [evaluate_edges(generator.graph, graphs[t])['f1-score'] for t in range(1, max_tau+1)]\n",
    "        bics = [stopper.scores()[t] for t in range(1, max_tau+1)]\n",
    "        \n",
    "        eval_dict = {name + '_tn': confusion['tn'].tolist(), name + '_fp': confusion['fp'].tolist(),\n",
    "                     name + '_tp': confusion['tp'].tolist(), name + '_fn': confusion['fn'].tolist(),\n",
    "                     name + '_f1': f1_scores, name + '_bics': bics, name + '_added_edges': added_edges}\n",
    "        df_dict.update(eval_dict)\n",
    "        \n",
    "    df = pd.DataFrame(df_dict)\n",
    "    results = results.append(df, ignore_index=True)\n",
    "\n",
    "results.to_csv(results_path + f'experiment3-Alpha001.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualize $F_1$ for known $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T10:14:38.651270Z",
     "start_time": "2019-01-14T10:14:38.601656Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import sys\n",
    "eps = sys.float_info.epsilon\n",
    "\n",
    "def plot_f1_groupedbarchart(df_dict, title):\n",
    "    assert len(df_dict) > 0\n",
    "    #assert reduce(lambda x,y: np.all(x == y), map(lambda e:e.columns, grouped_result.values()))\n",
    "    bar_labels = [f'$\\\\tau + {c[1]}$' if c[1]>=0 else f'$\\\\tau - {abs(c[1])}$'\n",
    "                  for c in next(iter(grouped_result.values())).columns]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    ind = np.arange(len(bar_labels))\n",
    "    width = 0.7 / len(df_dict)\n",
    "    \n",
    "    plots = []\n",
    "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    for w_idx, (algo, f1s) in enumerate(df_dict.items()):\n",
    "        p = ax.bar(ind + w_idx*width + (width / 2), np.mean(f1s, axis=0), width, \n",
    "                   color=color_cycle[w_idx % len(color_cycle)],\n",
    "                   bottom=0, yerr=np.std(f1s, axis=0))\n",
    "        plots.append(p[0])\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(ind + (len(df_dict) * width) / 2)\n",
    "    ax.set_xticklabels(bar_labels)\n",
    "\n",
    "    ax.legend(plots, df_dict.keys())\n",
    "    ax.autoscale_view()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T10:14:51.626865Z",
     "start_time": "2019-01-14T10:14:43.296477Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "algorithms = [(pc_incremental, 'PC incremental'),\n",
    "              (pc_incremental_extensive, 'PC extensive'),\n",
    "              (pc_incremental_pc1, 'PC1 incremental'),\n",
    "              (None, 'PC1 non-incremental')]\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment1.csv')\n",
    "for group, result in results.groupby(['max time lag', 'autocorr']): # Group by ['dimension', 'incoming edges', 'autocorr'] as well?\n",
    "    tau = int(group[0])\n",
    "    autocorr = float(group[1])\n",
    "    grouped_result = {}\n",
    "    for _, name in algorithms:\n",
    "        algo_cols = [col for col in result.columns if col[:col.rfind('_')] == name]\n",
    "        df = result[algo_cols].rename(lambda c:('f1', int(c.split('_')[-1][2:])), axis='columns')\n",
    "        grouped_result[name] = df[sorted(df.columns)]\n",
    "    plot_f1_groupedbarchart(grouped_result, title=f'$F_1$ score for known $\\\\tau$ = {tau}, autocorr = {autocorr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize estimate $\\hat{\\tau}$ for unknown $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:08:35.948254Z",
     "start_time": "2019-01-14T17:08:31.695334Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "visualize = [(3, 3, 0), (3, 3, 0.75), (3, 4, 0)]\n",
    "names = ['PC1 incremental: BIC', 'PC1 incremental: Correlation',\n",
    "         'VAR: BIC', 'PC incremental: BIC', 'PC extensive: BIC']\n",
    "\n",
    "width = 0.4\n",
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "cols = [name + '_tau' for name in names]\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment2-Alpha001.csv')\n",
    "true_taus = np.unique(results['max time lag'])\n",
    "\n",
    "for group, result in results.groupby(['dimension', 'incoming edges', 'autocorr']): \n",
    "    \n",
    "    if group not in visualize:\n",
    "        continue\n",
    "    \n",
    "    dim = int(group[0])\n",
    "    in_edges = int(group[1])\n",
    "    autocorr = float(group[2])\n",
    "    \n",
    "    colors = plt.cm.CMRmap(np.linspace(0,1,len(names)+2))\n",
    "    plt.figure(dpi=200, figsize=(15, 8))\n",
    "    \n",
    "    \n",
    "    for tau in true_taus:\n",
    "        start_x = tau - (width+0.1)*(len(names))/2\n",
    "        end_x = tau + (width+0.1)*(len(names))/2\n",
    "        y = tau\n",
    "        plt.hlines(y, start_x, end_x, colors='grey')\n",
    "    \n",
    "    bps = []\n",
    "    for i, name in enumerate(names):\n",
    "        positions = [tau + (width+0.1)*(i - (len(names)-1)/2) for tau in true_taus]\n",
    "        arr = [result.loc[result['max time lag']==tau, cols[i]] for tau in true_taus]\n",
    "        bp = plt.boxplot(arr, positions=positions, widths=width, showfliers=False,\n",
    "                         whiskerprops={'color': colors[i+1]}, boxprops={'color': colors[i+1]},\n",
    "                         capprops={'color': colors[i+1]}, medianprops={'color': 'black'})\n",
    "        bps.append(bp)\n",
    "    \n",
    "    plt.xlabel('true $\\\\tau$')\n",
    "    plt.ylabel('estimated $\\\\hat{\\\\tau}$')\n",
    "    plt.xticks(true_taus, true_taus)\n",
    "    plt.title(f'$\\\\tau$ estimation for dimensionality={dim}, incoming edges={in_edges}, autocorr={autocorr}')\n",
    "    plt.xlim(min(true_taus)-(width+0.2)*len(names)/2, max(true_taus)+(width+0.2)*len(names)/2)\n",
    "    \n",
    "    plt.legend([bps[i]['whiskers'][0] for i in range(len(names))], names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T17:13:21.888308Z",
     "start_time": "2019-01-14T17:13:21.768448Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "visualize = [(10, 3, 3, 0.75)]\n",
    "names = ['PC1 incremental', 'PC extensive', 'PC incremental']\n",
    "prop = 'fn'\n",
    "\n",
    "width = 0.4\n",
    "results_path = 'notebooks/ICML/icml_results/'\n",
    "\n",
    "results = pd.read_csv(results_path + 'experiment3-Alpha001.csv')\n",
    "true_taus = np.unique(results['max time lag'])\n",
    "\n",
    "for group, result in results.groupby(['max time lag', 'dimension', 'incoming edges', 'autocorr', 'run']): \n",
    "    \n",
    "    tau = int(group[0])\n",
    "    dim = int(group[1])\n",
    "    in_edges = int(group[2])\n",
    "    autocorr = float(group[3])\n",
    "    run = int(group[4])\n",
    "    \n",
    "    if (tau, dim, in_edges, autocorr) not in visualize:\n",
    "        continue\n",
    "    \n",
    "    colors = plt.cm.CMRmap(np.linspace(0,1,len(names)+2))\n",
    "    plt.figure(dpi=200, figsize=(15, 8))\n",
    "    \n",
    "    x = result['tau estimate']\n",
    "    for i, name in enumerate(names):\n",
    "        y = result[name + '_' + prop]\n",
    "        plt.plot(x, y, color=colors[i+1], label=name)\n",
    "    \n",
    "    plt.xlabel('iteration $\\\\tau$')\n",
    "    plt.ylabel(prop)\n",
    "    plt.title(f'{prop} for dimensionality={dim}, incoming edges={in_edges}, autocorr={autocorr}, run={run}')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "notify_time": "30",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
