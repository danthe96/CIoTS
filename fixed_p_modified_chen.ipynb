{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcus/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from CIoTS import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ps = list(range(4, 9, 2))\n",
    "test_ps = list(range(2, 11, 2))\n",
    "runs = 20\n",
    "dimensions = 4\n",
    "data_length = 10000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = pd.DataFrame(columns=['true_p', 'p', 'mean_f1', 'std_f1'])\n",
    "runtimes = pd.DataFrame(columns=['true_p', 'p', 'mean_time', 'std_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: p=4 run=1 p_test=2 exec_time=2.0252604484558105\n",
      "done: p=4 run=1 p_test=4 exec_time=7.836875915527344\n",
      "done: p=4 run=1 p_test=6 exec_time=21.853820323944092\n"
     ]
    }
   ],
   "source": [
    "for p in max_ps:\n",
    "    incoming_edges = 3 #max(ceil(dimensions*p/3), 1)\n",
    "    \n",
    "    f1 = {p_test: [] for p_test in test_ps}\n",
    "    runtime = {p_test: [] for p_test in test_ps}\n",
    "    \n",
    "    for run in range(runs):\n",
    "        generator = CausalTSGenerator(dimensions=dimensions, max_p=p, data_length=data_length, incoming_edges=incoming_edges)\n",
    "        ts = generator.generate()\n",
    "            \n",
    "        for p_test in test_ps:\n",
    "            start_time = time.time()\n",
    "            predicted_graph = pc_chen_modified(partial_corr_test, ts, p_test, alpha)\n",
    "            exec_time = time.time()-start_time\n",
    "            \n",
    "            f1[p_test].append(evaluate_edges(generator.graph, predicted_graph)['f1-score'])\n",
    "            runtime[p_test].append(exec_time)\n",
    "            print('done: p='+ str(p) + ' run='+str(run+1) + ' p_test='+str(p_test) + ' exec_time='+str(exec_time))\n",
    "    \n",
    "    for p_test in test_ps:\n",
    "        f1_scores = f1_scores.append({'true_p': p, 'p': p_test, 'mean_f1': np.mean(f1[p_test]),\n",
    "                                      'std_f1': np.std(f1[p_test])}, ignore_index=True)\n",
    "        runtimes = runtimes.append({'true_p': p, 'p': p_test, 'mean_time': np.mean(runtime[p_test]),\n",
    "                                    'std_time': np.std(runtime[p_test])}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('f1 scores for differen p')\n",
    "plt.xlabel('assumed p')\n",
    "plt.ylabel('mean f1')\n",
    "handles = []\n",
    "labels = []\n",
    "for p in max_ps:\n",
    "    plt.errorbar(x=f1_scores.loc[f1_scores['true_p']==p, 'p'],\n",
    "                 y=f1_scores.loc[f1_scores['true_p']==p, 'mean_f1'],\n",
    "                 yerr=f1_scores.loc[f1_scores['true_p']==p, 'std_f1'],\n",
    "                 label='true p='+str(p))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
