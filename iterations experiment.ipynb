{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T18:15:24.488713Z",
     "start_time": "2018-06-08T18:15:24.472036Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T18:23:02.548600Z",
     "start_time": "2018-06-08T18:23:01.549492Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from math import log\n",
    "from CIoTS import *\n",
    "from tqdm import trange\n",
    "import json\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-08T18:23:02.552837Z",
     "start_time": "2018-06-08T18:23:02.549995Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = 20\n",
    "max_p = 20\n",
    "dimensions = 3\n",
    "data_length = 10000\n",
    "alpha = 0.05\n",
    "incoming_edges = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['run', 'p', 'method', 'iteration p', 'f1', 'fpr', 'precision', 'recall', 'bic', 'time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for p in trange(2, max_p+2, 2):\n",
    "    for run in trange(runs):        \n",
    "        # generate graph and data\n",
    "        generator = CausalTSGenerator(dimensions=dimensions, max_p=p, data_length=data_length,\n",
    "                                      incoming_edges=incoming_edges)\n",
    "        ts = generator.generate()\n",
    "        data.append({'graph': generator.graph, 'ts': ts})\n",
    "        \n",
    "        # incremental pc\n",
    "        f1 = []\n",
    "        fpr = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        p_iters = []\n",
    "        time_iters = []\n",
    "        bic_iters = []\n",
    "        _, graphs, times, bics = pc_incremental(partial_corr_test, ts, alpha, 2*max_p, \n",
    "                                                verbose=True, patiency=2*max_p)\n",
    "        for p_iter, g in graphs.items():\n",
    "            eval_result = evaluate_edges(generator.graph, g)\n",
    "            f1.append(eval_result['f1-score'])\n",
    "            precision.append(eval_result['precision'])\n",
    "            recall.append(eval_result['TPR'])\n",
    "            fpr.append(eval_result['FPR'])\n",
    "            p_iters.append(p_iter)\n",
    "            time_iters.append(times[p_iter])\n",
    "            bic_iters.append(bics[p_iter])\n",
    "        results = results.append(pd.DataFrame({'run': [run]*len(f1), 'p': [p]*len(f1), 'iteration p': p_iters, \n",
    "                                               'f1': f1, 'fpr': fpr, 'recall': recall, 'precision': precision, \n",
    "                                               'bic': bic_iters, 'time': time_iters, 'method': ['incremental']*len(f1)}), \n",
    "                                 ignore_index=True, sort=True)\n",
    "        \n",
    "        \n",
    "        # incremental pc extensive\n",
    "        f1 = []\n",
    "        fpr = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        p_iters = []\n",
    "        time_iters = []\n",
    "        bic_iters = []\n",
    "        _, graphs, times, bics = pc_incremental_extensive(partial_corr_test, ts, alpha, 2*max_p, \n",
    "                                                          verbose=True, patiency=2*max_p)\n",
    "        for p_iter, g in graphs.items():\n",
    "            eval_result = evaluate_edges(generator.graph, g)\n",
    "            f1.append(eval_result['f1-score'])\n",
    "            precision.append(eval_result['precision'])\n",
    "            recall.append(eval_result['TPR'])\n",
    "            fpr.append(eval_result['FPR'])\n",
    "            p_iters.append(p_iter)\n",
    "            time_iters.append(times[p_iter])\n",
    "            bic_iters.append(bics[p_iter])\n",
    "        results = results.append(pd.DataFrame({'run': [run]*len(f1), 'p': [p]*len(f1), 'iteration p': p_iters, \n",
    "                                               'f1': f1, 'fpr': fpr, 'recall': recall, 'precision': precision, \n",
    "                                               'bic': bic_iters, 'time': time_iters, 'method': ['extensive']*len(f1)}), \n",
    "                                 ignore_index=True)\n",
    "        \n",
    "        # incremental pc subsets\n",
    "        f1 = []\n",
    "        fpr = []\n",
    "        precision = []\n",
    "        recall = []\n",
    "        p_iters = []\n",
    "        time_iters = []\n",
    "        bic_iters = []\n",
    "        _, graphs, times, bics = pc_incremental_subsets(partial_corr_test, ts, alpha, 2*max_p, \n",
    "                                                        verbose=True, patiency=2*max_p)\n",
    "        for p_iter, g in graphs.items():\n",
    "            eval_result = evaluate_edges(generator.graph, g)\n",
    "            f1.append(eval_result['f1-score'])\n",
    "            precision.append(eval_result['precision'])\n",
    "            recall.append(eval_result['TPR'])\n",
    "            fpr.append(eval_result['FPR'])\n",
    "            p_iters.append(p_iter)\n",
    "            time_iters.append(times[p_iter])\n",
    "            bic_iters.append(bics[p_iter])\n",
    "        results = results.append(pd.DataFrame({'run': [run]*len(f1), 'p': [p]*len(f1), 'iteration p': p_iters, \n",
    "                                               'f1': f1, 'fpr': fpr, 'recall': recall, 'precision': precision, \n",
    "                                               'bic': bic_iters, 'time': time_iters, 'method': ['subsets']*len(f1)}), \n",
    "                                 ignore_index=True)\n",
    "        results.to_csv('results/iterations/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data(data, file):\n",
    "    json_data = []\n",
    "    for d in data:\n",
    "        json_data.append({'graph': nx.to_dict_of_lists(d['graph']), 'ts': d['ts'].to_dict()})\n",
    "    with open(file, 'w+') as fp:\n",
    "        json.dump(json_data, fp)\n",
    "        \n",
    "def load_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r') as fp:\n",
    "        json_data = json.load(fp)\n",
    "    for d in json_data:\n",
    "        graph = nx.from_dict_of_lists(d['graph'], nx.DiGraph())\n",
    "        ts = pd.DataFrame.from_dict(d['ts'])\n",
    "        ts.index = ts.index.astype(int)\n",
    "        ts = ts.sort_index()\n",
    "        data.append({'graph': graph,'ts': ts})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump_data(data, 'results/iterations/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_data('results/iterations/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 1/200 [00:03<11:05,  3.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 2/200 [00:05<08:38,  2.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|â–         | 3/200 [00:07<08:27,  2.58s/it]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "comp_results = pd.DataFrame(columns=['run', 'p', 'method','iteration p', 'f1', 'fpr', 'precision', 'recall', 'time'])\n",
    "for i in trange(len(loaded_data)):\n",
    "    graph = loaded_data[i]['graph']\n",
    "    ts = loaded_data[i]['ts']\n",
    "    run = i % 20\n",
    "    p = int(len(graph.nodes())/dimensions - 1)\n",
    "    \n",
    "    start_time = time()\n",
    "    predicted_graph = pc_chen_modified(partial_corr_test, ts, p, alpha)\n",
    "    runtime = time() - start_time\n",
    "    eval_result = evaluate_edges(graph, predicted_graph)\n",
    "    comp_results = comp_results.append({'run': run, 'p': p, 'iteration p': p, 'method': 'real',\n",
    "                                        'f1': eval_result['f1-score'],\n",
    "                                        'precision': eval_result['precision'],\n",
    "                                        'recall': eval_result['TPR'],\n",
    "                                        'fpr': eval_result['FPR'],\n",
    "                                        'time': runtime},\n",
    "                                       ignore_index=True)\n",
    "    \n",
    "    \n",
    "    start_time = time()\n",
    "    var_ranking, _ = var_order_select(ts, 2*(max_p-2), ['bic'])\n",
    "    p_est = var_ranking['bic'][0]\n",
    "    predicted_graph = pc_chen_modified(partial_corr_test, ts, p_est, alpha)\n",
    "    runtime = time() - start_time\n",
    "    eval_result = evaluate_edges(graph, predicted_graph)\n",
    "    comp_results = comp_results.append({'run': run, 'p': p, 'iteration p': p_est, 'method': 'bic', \n",
    "                                        'f1': eval_result['f1-score'],\n",
    "                                        'precision': eval_result['precision'],\n",
    "                                        'recall': eval_result['TPR'],\n",
    "                                        'fpr': eval_result['FPR'],\n",
    "                                        'time': runtime},\n",
    "                                       ignore_index=True)\n",
    "    comp_results.to_csv('results/iterations/comp_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
