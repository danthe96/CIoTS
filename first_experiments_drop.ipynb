{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:10.969449Z",
     "start_time": "2018-06-18T11:59:10.952075Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:11.976911Z",
     "start_time": "2018-06-18T11:59:10.970881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcus/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from CIoTS import *\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:12.004112Z",
     "start_time": "2018-06-18T11:59:11.978469Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = 20\n",
    "max_p = 22\n",
    "dimensions = 3\n",
    "data_length = 10000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:12.030464Z",
     "start_time": "2018-06-18T11:59:12.005666Z"
    }
   },
   "outputs": [],
   "source": [
    "ics = [\"aic\", \"bic\", \"hqic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T12:33:16.072889Z",
     "start_time": "2018-06-18T12:33:16.042249Z"
    }
   },
   "outputs": [],
   "source": [
    "p_estimations = pd.DataFrame(columns=['p' ,'method', 'mean_p', 'std_p'])\n",
    "scores = pd.DataFrame(columns=['p' ,'method', 'mean_f1', 'std_f1', 'mean_recall', 'std_recall',\n",
    "                               'mean_precision', 'std_precision', 'mean_fpr', 'std_fpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:11:42.088739Z",
     "start_time": "2018-06-18T12:33:16.940040Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:19<06:02, 19.07s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:37<05:35, 18.65s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:55<05:15, 18.58s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:28<05:54, 22.16s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [07:19<21:58, 87.91s/it]\u001b[A\n",
      " 30%|███       | 6/20 [07:31<17:32, 75.18s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [08:37<16:00, 73.92s/it]\u001b[A\n",
      " 40%|████      | 8/20 [11:18<16:58, 84.87s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [11:42<14:18, 78.08s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [16:12<16:12, 97.23s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [17:44<14:30, 96.76s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [17:54<11:56, 89.52s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [19:00<10:14, 87.76s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [19:10<08:13, 82.20s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [20:04<06:41, 80.29s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [20:14<05:03, 75.91s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [20:34<03:37, 72.62s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [22:03<02:27, 73.53s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [22:13<01:10, 70.20s/it]\u001b[A\n",
      "100%|██████████| 20/20 [23:33<00:00, 70.66s/it]\u001b[A\n",
      " 10%|█         | 1/10 [23:33<3:31:58, 1413.20s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:28<08:56, 28.23s/it]\u001b[A\n",
      " 10%|█         | 2/20 [02:35<23:21, 77.89s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [03:14<18:24, 64.96s/it]\u001b[A\n",
      " 20%|██        | 4/20 [04:04<16:18, 61.17s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [04:52<14:37, 58.52s/it]\u001b[A\n",
      " 30%|███       | 6/20 [05:14<12:14, 52.49s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [05:41<10:35, 48.86s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "for p in trange(2, max_p, 2):\n",
    "    incoming_edges = 3\n",
    "    f1 = {ic: [] for ic in ics}\n",
    "    f1.update({'incremental_' + ic: [] for ic in ics})\n",
    "    f1['real'] = []\n",
    "    \n",
    "    precision = {ic: [] for ic in ics}\n",
    "    precision.update({'incremental_' + ic: [] for ic in ics})\n",
    "    precision['real'] = []\n",
    "    \n",
    "    recall = {ic: [] for ic in ics}\n",
    "    recall.update({'incremental_' + ic: [] for ic in ics})\n",
    "    recall['real'] = []\n",
    "    \n",
    "    fpr = {ic: [] for ic in ics}\n",
    "    fpr.update({'incremental_' + ic: [] for ic in ics})\n",
    "    fpr['real'] = []\n",
    "    \n",
    "    p_est = {ic: [] for ic in ics}\n",
    "    p_est.update({'incremental_' + ic: [] for ic in ics})\n",
    "    \n",
    "    for i in trange(runs):\n",
    "        generator = CausalTSGenerator(dimensions=dimensions, max_p=p, data_length=data_length,\n",
    "                                      incoming_edges=incoming_edges)\n",
    "        ts = generator.generate()\n",
    "        predicted_graph = pc_chen_modified(partial_corr_test, ts, p, alpha)\n",
    "        \n",
    "        eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "        f1['real'].append(eval_result['f1-score'])\n",
    "        recall['real'].append(eval_result['TPR'])\n",
    "        fpr['real'].append(eval_result['FPR'])\n",
    "        precision['real'].append(eval_result['precision'])\n",
    "        \n",
    "        # VAR estimation\n",
    "        var_ranking, var_scores = var_order_select(ts, 2*(max_p-2), ics, drop=True) \n",
    "        for ic in ics:\n",
    "            predicted_graph = pc_chen_modified(partial_corr_test, ts, var_ranking[ic][0], alpha)\n",
    "            eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "            \n",
    "            p_est[ic].append(var_ranking[ic][0])\n",
    "            f1[ic].append(eval_result['f1-score'])\n",
    "            recall[ic].append(eval_result['TPR'])\n",
    "            fpr[ic].append(eval_result['FPR'])\n",
    "            precision[ic].append(eval_result['precision'])\n",
    "        \n",
    "        # incremental\n",
    "        for ic in ics:\n",
    "            predicted_graph = pc_incremental(partial_corr_test, ts, 0.05, 2*(max_p-2), ic=ic)\n",
    "            eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "            \n",
    "            p_est['incremental_' + ic].append(len(predicted_graph.nodes())/dimensions - 1)\n",
    "            f1['incremental_' + ic].append(eval_result['f1-score'])\n",
    "            recall['incremental_' + ic].append(eval_result['TPR'])\n",
    "            fpr['incremental_' + ic].append(eval_result['FPR'])\n",
    "            precision['incremental_' + ic].append(eval_result['precision'])\n",
    "    \n",
    "    \n",
    "    scores = scores.append({'p': p, 'method': 'real',\n",
    "                            'mean_f1': np.mean(f1['real']), 'std_f1': np.std(f1['real']),\n",
    "                            'mean_recall': np.mean(recall['real']), 'std_recall': np.std(recall['real']),\n",
    "                            'mean_precision': np.mean(precision['real']), 'std_precision': np.std(precision['real']),\n",
    "                            'mean_fpr': np.mean(fpr['real']), 'std_fpr': np.std(fpr['real'])},\n",
    "                           ignore_index=True)\n",
    "    for ic in ics:\n",
    "        p_estimations = p_estimations.append({'p': p, 'method': ic, 'mean_p': np.mean(p_est[ic]), \n",
    "                                              'std_p': np.std(p_est[ic])},\n",
    "                                             ignore_index=True)\n",
    "        scores = scores.append({'p': p, 'method': ic,\n",
    "                                'mean_f1': np.mean(f1[ic]), 'std_f1': np.std(f1[ic]),\n",
    "                                'mean_recall': np.mean(recall[ic]), 'std_recall': np.std(recall[ic]),\n",
    "                                'mean_precision': np.mean(precision[ic]), 'std_precision': np.std(precision[ic]),\n",
    "                                'mean_fpr': np.mean(fpr[ic]), 'std_fpr': np.std(fpr[ic])},\n",
    "                               ignore_index=True)\n",
    "   \n",
    "    for ic in ics:\n",
    "        p_estimations = p_estimations.append({'p': p, 'method': 'incremental_' + ic, \n",
    "                                              'mean_p': np.mean(p_est['incremental_' + ic]),\n",
    "                                              'std_p': np.std(p_est['incremental_' + ic])},\n",
    "                                             ignore_index=True)\n",
    "        scores = scores.append({'p': p, 'method': 'incremental_' + ic,\n",
    "                                'mean_f1': np.mean(f1['incremental_' + ic]), 'std_f1': np.std(f1['incremental_' + ic]),\n",
    "                                'mean_recall': np.mean(recall['incremental_' + ic]),\n",
    "                                'std_recall': np.std(recall['incremental_' + ic]),\n",
    "                                'mean_precision': np.mean(precision['incremental_' + ic]),\n",
    "                                'std_precision': np.std(precision['incremental_' + ic]),\n",
    "                                'mean_fpr': np.mean(fpr['incremental_' + ic]),\n",
    "                                'std_fpr': np.std(fpr['incremental_' + ic])},\n",
    "                               ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:11:42.088739Z",
     "start_time": "2018-06-18T12:33:16.940040Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.to_csv('scores_drop.csv')\n",
    "p_estimations.to_csv('p_estimations_drop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores var estimation')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "for i in range(len(ics)):\n",
    "    plt.subplot(len(ics), 1, i+1)\n",
    "    ic = ics[i]\n",
    "    plt.errorbar(x=scores.loc[scores['method']==ic, 'p'],\n",
    "                 y=scores.loc[scores['method']==ic, 'mean_f1'],\n",
    "                 yerr=scores.loc[scores['method']==ic, 'std_f1'],\n",
    "                 label=ic)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores incremental')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "for i in range(len(ics)):\n",
    "    plt.subplot(len(ics), 1, i+1)\n",
    "    ic = ics[i]\n",
    "    plt.errorbar(x=scores.loc[scores['method']=='incremental_' + ic, 'p'],\n",
    "                 y=scores.loc[scores['method']=='incremental_' + ic, 'mean_f1'],\n",
    "                 yerr=scores.loc[scores['method']=='incremental_' + ic, 'std_f1'],\n",
    "                 label='incremental_' + ic)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores compared')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='real', 'p'],\n",
    "             y=scores.loc[scores['method']=='real', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='real', 'std_f1'],\n",
    "             label='real')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='bic', 'p'],\n",
    "             y=scores.loc[scores['method']=='bic', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='bic', 'std_f1'],\n",
    "             label='bic')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='incremental_bic', 'p'],\n",
    "             y=scores.loc[scores['method']=='incremental_bic', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='incremental_bic', 'std_f1'],\n",
    "             label='incremental_bic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
