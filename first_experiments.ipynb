{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:10.969449Z",
     "start_time": "2018-06-18T11:59:10.952075Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:11.976911Z",
     "start_time": "2018-06-18T11:59:10.970881Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcus/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from CIoTS import *\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:12.004112Z",
     "start_time": "2018-06-18T11:59:11.978469Z"
    }
   },
   "outputs": [],
   "source": [
    "runs = 20\n",
    "max_p = 22\n",
    "dimensions = 3\n",
    "data_length = 10000\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T11:59:12.030464Z",
     "start_time": "2018-06-18T11:59:12.005666Z"
    }
   },
   "outputs": [],
   "source": [
    "ics = [\"aic\", \"bic\", \"hqic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T12:33:16.072889Z",
     "start_time": "2018-06-18T12:33:16.042249Z"
    }
   },
   "outputs": [],
   "source": [
    "p_estimations = pd.DataFrame(columns=['p' ,'method', 'mean_p', 'std_p'])\n",
    "scores = pd.DataFrame(columns=['p' ,'method', 'mean_f1', 'std_f1', 'mean_recall', 'std_recall',\n",
    "                               'mean_precision', 'std_precision', 'mean_fpr', 'std_fpr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:11:42.088739Z",
     "start_time": "2018-06-18T12:33:16.940040Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:07<02:13,  7.03s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:22<03:20, 11.11s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [01:45<09:59, 35.24s/it]\u001b[A\n",
      " 20%|██        | 4/20 [02:21<09:26, 35.42s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [04:29<13:28, 53.93s/it]\u001b[A\n",
      " 30%|███       | 6/20 [04:38<10:50, 46.46s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [04:52<09:03, 41.79s/it]\u001b[A\n",
      " 40%|████      | 8/20 [05:09<07:43, 38.66s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [07:11<08:47, 48.00s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [07:39<07:39, 45.93s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:01<06:34, 43.79s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [08:13<05:29, 41.13s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [08:34<04:37, 39.59s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [08:43<03:44, 37.42s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [10:34<03:31, 42.31s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [10:49<02:42, 40.62s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [11:18<01:59, 39.89s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [11:26<01:16, 38.12s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [11:36<00:36, 36.68s/it]\u001b[A\n",
      "100%|██████████| 20/20 [11:56<00:00, 35.83s/it]\u001b[A\n",
      " 10%|█         | 1/10 [11:56<1:47:30, 716.75s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▌         | 1/20 [00:13<04:09, 13.11s/it]\u001b[A\n",
      " 10%|█         | 2/20 [00:35<05:23, 17.96s/it]\u001b[A\n",
      " 15%|█▌        | 3/20 [00:59<05:39, 19.99s/it]\u001b[A\n",
      " 20%|██        | 4/20 [01:18<05:12, 19.50s/it]\u001b[A\n",
      " 25%|██▌       | 5/20 [03:08<09:25, 37.72s/it]\u001b[A\n",
      " 30%|███       | 6/20 [06:00<14:01, 60.13s/it]\u001b[A\n",
      " 35%|███▌      | 7/20 [06:18<11:42, 54.03s/it]\u001b[A\n",
      " 40%|████      | 8/20 [07:39<11:28, 57.40s/it]\u001b[A\n",
      " 45%|████▌     | 9/20 [08:13<10:02, 54.79s/it]\u001b[A\n",
      " 50%|█████     | 10/20 [08:25<08:25, 50.57s/it]\u001b[A\n",
      " 55%|█████▌    | 11/20 [08:43<07:08, 47.62s/it]\u001b[A\n",
      " 60%|██████    | 12/20 [09:12<06:08, 46.02s/it]\u001b[A\n",
      " 65%|██████▌   | 13/20 [11:32<06:12, 53.27s/it]\u001b[A\n",
      " 70%|███████   | 14/20 [11:47<05:03, 50.55s/it]\u001b[A\n",
      " 75%|███████▌  | 15/20 [12:17<04:05, 49.19s/it]\u001b[A\n",
      " 80%|████████  | 16/20 [14:58<03:44, 56.18s/it]\u001b[A\n",
      " 85%|████████▌ | 17/20 [15:23<02:42, 54.33s/it]\u001b[A\n",
      " 90%|█████████ | 18/20 [16:07<01:47, 53.73s/it]\u001b[A\n",
      " 95%|█████████▌| 19/20 [17:34<00:55, 55.49s/it]\u001b[A\n",
      "100%|██████████| 20/20 [17:46<00:00, 53.35s/it]\u001b[A\n",
      " 20%|██        | 2/10 [29:43<1:58:55, 891.88s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for p in trange(2, max_p, 2):\n",
    "    incoming_edges = 3\n",
    "    f1 = {ic: [] for ic in ics}\n",
    "    f1.update({'incremental_' + ic: [] for ic in ics})\n",
    "    f1['real'] = []\n",
    "    \n",
    "    precision = {ic: [] for ic in ics}\n",
    "    precision.update({'incremental_' + ic: [] for ic in ics})\n",
    "    precision['real'] = []\n",
    "    \n",
    "    recall = {ic: [] for ic in ics}\n",
    "    recall.update({'incremental_' + ic: [] for ic in ics})\n",
    "    recall['real'] = []\n",
    "    \n",
    "    fpr = {ic: [] for ic in ics}\n",
    "    fpr.update({'incremental_' + ic: [] for ic in ics})\n",
    "    fpr['real'] = []\n",
    "    \n",
    "    p_est = {ic: [] for ic in ics}\n",
    "    p_est.update({'incremental_' + ic: [] for ic in ics})\n",
    "    \n",
    "    for i in trange(runs):\n",
    "        generator = CausalTSGenerator(dimensions=dimensions, max_p=p, data_length=data_length,\n",
    "                                      incoming_edges=incoming_edges)\n",
    "        ts = generator.generate()\n",
    "        predicted_graph = pc_chen_modified(partial_corr_test, ts, p, alpha)\n",
    "        \n",
    "        eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "        f1['real'].append(eval_result['f1-score'])\n",
    "        recall['real'].append(eval_result['TPR'])\n",
    "        fpr['real'].append(eval_result['FPR'])\n",
    "        precision['real'].append(eval_result['precision'])\n",
    "        \n",
    "        # VAR estimation\n",
    "        var_ranking, var_scores = var_order_select(ts, 2*(max_p-2), ics) \n",
    "        for ic in ics:\n",
    "            predicted_graph = pc_chen_modified(partial_corr_test, ts, var_ranking[ic][0], alpha)\n",
    "            eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "            \n",
    "            p_est[ic].append(var_ranking[ic][0])\n",
    "            f1[ic].append(eval_result['f1-score'])\n",
    "            recall[ic].append(eval_result['TPR'])\n",
    "            fpr[ic].append(eval_result['FPR'])\n",
    "            precision[ic].append(eval_result['precision'])\n",
    "        \n",
    "        # incremental\n",
    "        for ic in ics:\n",
    "            predicted_graph = pc_incremental(partial_corr_test, ts, 0.05, 2*(max_p-2), ic=ic)\n",
    "            eval_result = evaluate_edges(generator.graph, predicted_graph)\n",
    "            \n",
    "            p_est['incremental_' + ic].append(len(predicted_graph.nodes())/dimensions - 1)\n",
    "            f1['incremental_' + ic].append(eval_result['f1-score'])\n",
    "            recall['incremental_' + ic].append(eval_result['TPR'])\n",
    "            fpr['incremental_' + ic].append(eval_result['FPR'])\n",
    "            precision['incremental_' + ic].append(eval_result['precision'])\n",
    "    \n",
    "    \n",
    "    scores = scores.append({'p': p, 'method': 'real',\n",
    "                            'mean_f1': np.mean(f1['real']), 'std_f1': np.std(f1['real']),\n",
    "                            'mean_recall': np.mean(recall['real']), 'std_recall': np.std(recall['real']),\n",
    "                            'mean_precision': np.mean(precision['real']), 'std_precision': np.std(precision['real']),\n",
    "                            'mean_fpr': np.mean(fpr['real']), 'std_fpr': np.std(fpr['real'])},\n",
    "                           ignore_index=True)\n",
    "    for ic in ics:\n",
    "        p_estimations = p_estimations.append({'p': p, 'method': ic, 'mean_p': np.mean(p_est[ic]), \n",
    "                                              'std_p': np.std(p_est[ic])},\n",
    "                                             ignore_index=True)\n",
    "        scores = scores.append({'p': p, 'method': ic,\n",
    "                                'mean_f1': np.mean(f1[ic]), 'std_f1': np.std(f1[ic]),\n",
    "                                'mean_recall': np.mean(recall[ic]), 'std_recall': np.std(recall[ic]),\n",
    "                                'mean_precision': np.mean(precision[ic]), 'std_precision': np.std(precision[ic]),\n",
    "                                'mean_fpr': np.mean(fpr[ic]), 'std_fpr': np.std(fpr[ic])},\n",
    "                               ignore_index=True)\n",
    "   \n",
    "    for ic in ics:\n",
    "        p_estimations = p_estimations.append({'p': p, 'method': 'incremental_' + ic, \n",
    "                                              'mean_p': np.mean(p_est['incremental_' + ic]),\n",
    "                                              'std_p': np.std(p_est['incremental_' + ic])},\n",
    "                                             ignore_index=True)\n",
    "        scores = scores.append({'p': p, 'method': 'incremental_' + ic,\n",
    "                                'mean_f1': np.mean(f1['incremental_' + ic]), 'std_f1': np.std(f1['incremental_' + ic]),\n",
    "                                'mean_recall': np.mean(recall['incremental_' + ic]),\n",
    "                                'std_recall': np.std(recall['incremental_' + ic]),\n",
    "                                'mean_precision': np.mean(precision['incremental_' + ic]),\n",
    "                                'std_precision': np.std(precision['incremental_' + ic]),\n",
    "                                'mean_fpr': np.mean(fpr['incremental_' + ic]),\n",
    "                                'std_fpr': np.std(fpr['incremental_' + ic])},\n",
    "                               ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:11:42.088739Z",
     "start_time": "2018-06-18T12:33:16.940040Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores.to_csv('scores.csv')\n",
    "p_estimations.to_csv('p_estimations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare VAR p estimation with different information criterions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T16:12:02.817310Z",
     "start_time": "2018-06-18T16:12:02.761118Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores var estimation')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "for i in range(len(ics)):\n",
    "    plt.subplot(len(ics), 1, i+1)\n",
    "    ic = ics[i]\n",
    "    plt.errorbar(x=scores.loc[scores['method']==ic, 'p'],\n",
    "                 y=scores.loc[scores['method']==ic, 'mean_f1'],\n",
    "                 yerr=scores.loc[scores['method']==ic, 'std_f1'],\n",
    "                 label=ic)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare incremental approach with differen information criterions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores incremental')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "for i in range(len(ics)):\n",
    "    plt.subplot(len(ics), 1, i+1)\n",
    "    ic = ics[i]\n",
    "    plt.errorbar(x=scores.loc[scores['method']=='incremental_' + ic, 'p'],\n",
    "                 y=scores.loc[scores['method']=='incremental_' + ic, 'mean_f1'],\n",
    "                 yerr=scores.loc[scores['method']=='incremental_' + ic, 'std_f1'],\n",
    "                 label='incremental_' + ic)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparision to Chen with known p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.title('f1 scores compared')\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('f1')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='real', 'p'],\n",
    "             y=scores.loc[scores['method']=='real', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='real', 'std_f1'],\n",
    "             label='real')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='bic', 'p'],\n",
    "             y=scores.loc[scores['method']=='bic', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='bic', 'std_f1'],\n",
    "             label='bic')\n",
    "\n",
    "plt.errorbar(x=scores.loc[scores['method']=='incremental_bic', 'p'],\n",
    "             y=scores.loc[scores['method']=='incremental_bic', 'mean_f1'],\n",
    "             yerr=scores.loc[scores['method']=='incremental_bic', 'std_f1'],\n",
    "             label='incremental_bic')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
